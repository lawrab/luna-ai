# luna/config.py
"""
Centralized configuration settings for the L.U.N.A. assistant.
"""

# Name of the Ollama model to use for the assistant
LLM_MODEL = "llama3"